{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Books Ever\n",
    "\n",
    "#### Audiencia y motivacion\n",
    "\n",
    "Como un acérrimo lector siempre me encuentro en la busqueda de nuevos titulos para leer y recomendando a amigos y conocidos sus posibles nuevas lecturas. \n",
    "En ambos casos es comun que se presente la misma problematica: es muy dificil poder dar con lo que busco, generalmente por falta de conocimiento sobre nuevos lanzamientos o libros no tan nuevos pero que fueron escritos por autores que aún no tuve la oportunidad de conocer. Por esto, apenas descubri el dataset con el que estoy trabajando se me ocurrio hacer un sistema de recomendacion de libros basado en las puntuaciones que un usuario le ponga a titulos que ya leyó.\n",
    "\n",
    "---\n",
    "\n",
    "#### Descripcion\n",
    "\n",
    "Best Books Ever es un data set extraido de la pagina GoodReads en donde los usuarios (entre otras cosas) pueden calificar los libros que hayan leido, este dataset recopila todas las puntuaciones para cada libro ademas de agregar informacion de los mismos como el genero al que pertenecen, la fecha de publicacion o el formato en el que fue publicado el libro.\n",
    "Las columnas con las que cuento son:\n",
    "\n",
    "\n",
    "| Columna | Descripcion |\n",
    "| -------------- | ------------- |\n",
    "| bookId | ID del libro como en goodreads.com |\n",
    "| title | Titulo |\n",
    "| author | Autor/a |\n",
    "| rating | Calificacion global en goodreads |\n",
    "| language | Idioma |\n",
    "| genres | Lista de generos | \n",
    "| bookFormat | Tipo de encuadernado |\n",
    "| pages | Cantidad de paginas |\n",
    "| publishDate | Fecha de publicacion |\n",
    "| firstPublishDate | Fecha de publicacion de la primer edicion |\n",
    "| numRatings | Cantidad de calificaciones |\n",
    "| likedPercent | Porcentaje de calificaciones mayores a dos estrellas |\n",
    "| price | Precio |\n",
    "| publishDecade | Decada de publicacion |\n",
    "| weightedRating | Rating aplicando shrinkage estimation |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BestBooksDS.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>price</th>\n",
       "      <th>publishDecade</th>\n",
       "      <th>weightedRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>374</td>\n",
       "      <td>2008-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6376780</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.329518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>4.50</td>\n",
       "      <td>English</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>paperback</td>\n",
       "      <td>870</td>\n",
       "      <td>2004-09-28</td>\n",
       "      <td>2003-06-21</td>\n",
       "      <td>2507623</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.498101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>English</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>paperback</td>\n",
       "      <td>324</td>\n",
       "      <td>2006-05-23</td>\n",
       "      <td>2060-07-11</td>\n",
       "      <td>4501075</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.279428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "\n",
       "                                       title  \\\n",
       "0                           The Hunger Games   \n",
       "1  Harry Potter and the Order of the Phoenix   \n",
       "2                      To Kill a Mockingbird   \n",
       "\n",
       "                                      author  rating language  \\\n",
       "0                            Suzanne Collins    4.33  English   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)    4.50  English   \n",
       "2                                 Harper Lee    4.28  English   \n",
       "\n",
       "                                              genres bookFormat  pages  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...  hardcover    374   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...  paperback    870   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...  paperback    324   \n",
       "\n",
       "  publishDate firstPublishDate  numRatings  likedPercent  price  \\\n",
       "0  2008-09-14              NaN     6376780          96.0   5.09   \n",
       "1  2004-09-28       2003-06-21     2507623          98.0   7.38   \n",
       "2  2006-05-23       2060-07-11     4501075          95.0   5.62   \n",
       "\n",
       "   publishDecade  weightedRating  \n",
       "0           2000        4.329518  \n",
       "1           2000        4.498101  \n",
       "2           2000        4.279428  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Validacion del modelo\n",
    "\n",
    "Al tratarse de un sistema de recomendaciones que utiliza un modelo de procesamiento de lenguaje natural basado en content-based filtering (ya que solo se trata de ver las similaridades entre distintos libros, no de predecir resultados en base a ratings de distintos usuarios como suelen hacer este tipo de sistemas), no poseo un set de datos etiquetado ni una variable objetivo, esto hace imposible decir si una recomendacion es o no buena de forma automatica ya que el valor de estas es totalmente subjetivo. Luego de mucha investigación, la unica forma de validacion que encontre es verificar manualmente la similaridad entre dichos libros. \n",
    "\n",
    "Por esto, continuando con lo trabajado en la entrega anterior probe modificar la forma de calcular la similaridad entre los vectores de palabras y tambien hacer un poco de ajuste de  hiperparametros, y comparar los resultados obtenidos para ver si puedo mejorar la performance del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Feature Engineering\n",
    "usando las variables author, genres y publishDecade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una copia del dataframe original\n",
    "metadata = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "features = ['author', 'genres']\n",
    "\n",
    "metadata['genres'] = metadata['genres'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que elimina los espacios, transforma a minuscula y en el caso de strings que contengan una coma, elimina todo el texto a partir de esta.\n",
    "def cleaner(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\").split(\",\")[0])\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpio las columnas 'author' y 'genres' con la funcion que acabo de crear\n",
    "for feature in features:\n",
    "    metadata[f'{feature}Clean'] = metadata[feature].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que devuelve un string concatenando las columnas 'author', 'publishDecade' y 'genres' del dataset utilizado con un espacio.\n",
    "def make_soup(x):\n",
    "    return ''.join(x['authorClean']) + ' '  +  ''.join(str(x['publishDecade'])) + ' ' + ' '.join(x['genresClean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo la informacion devuelta por la funcion 'make_soup' en una nueva columna 'soup' del dataset\n",
    "metadata['soup'] = metadata.apply(make_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    suzannecollins 2000 youngadult fiction dystopi...\n",
       "1    j.k.rowling 2000 fantasy youngadult fiction ma...\n",
       "2    harperlee 2000 classics fiction historicalfict...\n",
       "3    janeausten 2000 classics fiction romance histo...\n",
       "4    stepheniemeyer 2000 youngadult fantasy romance...\n",
       "Name: soup, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#asi se ven estos resultados\n",
    "metadata['soup'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(columns=['bookId', 'rating', 'language', 'genres', 'bookFormat', 'pages', 'publishDate', 'firstPublishDate', 'numRatings', 'likedPercent', 'price', 'authorClean', 'genresClean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\AppData\\Local\\Temp\\ipykernel_6360\\3045558770.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata['author'].iloc[i] = metadata['author'].iloc[i].split('(')[0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(metadata)):\n",
    "    metadata['author'].iloc[i] = metadata['author'].iloc[i].split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop_duplicates(subset=['title'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv('metadata.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Creacion del modelo de content-based filtering\n",
    "\n",
    "y probando distintas formas de medir la similaridad entre los vectores de texto e hyper tunning de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo un vector de relacion usando la columna recien creada\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(metadata['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49927, 24645)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecucion: 366.59633779525757 segundos\n"
     ]
    }
   ],
   "source": [
    "# uso la funcion cosine_similarity para calcular la similaridad entre los vectores de relacion\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "cos_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "print(f'Tiempo de ejecucion: {time.time() - start_time} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "\n",
    "poly_sim = polynomial_kernel(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poly_sim_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(poly_sim, 'poly_sim_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinicio los indices del dataframe metadata y creo una serie con los titulos e id de cada libro para poder relacionar los resultados de las predicciones con dicho dataframe\n",
    "metadata = metadata.reset_index()\n",
    "indices = pd.Series(metadata.index, index=metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una funcion que recibe un titulo como input y devuelve los 10 libros mas similares\n",
    "def get_recommendations(title, scores):\n",
    "    #encuentro el indice del titulo ingresado\n",
    "    idx = indices[title]\n",
    "\n",
    "    #busco los scores de similaridad con este libro\n",
    "    sim_scores = list(enumerate(scores[idx]))\n",
    "\n",
    "    #ordeno la lista de libros segun el score obtenido por cada uno\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #devuelvo los 10 mas similares (salteo el 1ro ya que el libro ingresado es siempre el mas similar a si mismo)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    #busco los indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #devuelvo los titulos de los libros mas similares\n",
    "    return metadata['title'].iloc[movie_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Hypertunning de Parametros\n",
    "\n",
    "Desepues de comparar los resultados de ambas formas de medir la similaridad de los vectores de texto se puede observar como los resultados son en su mayoria muy similares. la principal diferencia entre estas metricas es el tiempo de procesamiento, llevando el polynomial kernel un total de 679 segundos (11 minutos aprox.) y el cosine similarity un total de 370 segundos (6 minutos aprox.) llevandome esto a decidirme por usar cosine similarity.\n",
    "\n",
    "Una vez seleccionada la metrica a usar voy a hacer hypertunning de parametros y comparar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\AppData\\Local\\Temp\\ipykernel_9336\\4125564033.py:2: DeprecationWarning: This function is deprecated. Please call randint(0, 52429 + 1) instead\n",
      "  idx_test = np.random.random_integers(0, len(df), 4)\n"
     ]
    }
   ],
   "source": [
    "#genero 10 numeros aleatorios para usar como indices de libros que luego utilizare para evaluar los resultados\n",
    "idx_test = np.random.random_integers(0, len(df), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38463 30246  4610 25625]\n",
      "['The Tin Woodman of Oz', 'Το Αυτό-Τόμος ΙΙ', 'Hidden Figures', 'Hunting Annabelle']\n"
     ]
    }
   ],
   "source": [
    "libros_test = []\n",
    "\n",
    "#busco los titulos de los libros que tengan un index de los generados anteriormente\n",
    "for idx in idx_test:\n",
    "    libros_test.append(df['title'].iloc[idx])\n",
    "\n",
    "print(idx_test)\n",
    "print(libros_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DSVenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13723cc732d800d080f080aef13563e5c66f9dde8447ba8da4369e79b1b3e436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
